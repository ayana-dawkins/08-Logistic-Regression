{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metrics\n",
    "\n",
    "**GOALS**:\n",
    "\n",
    "- Compare Accuracy, Precision, and Recall metrics for different classifiers\n",
    "- Examine the Precision Recall tradeoff and understand appropriate determination of thresholds\n",
    "- Visualize Precision Recall tradeoff \n",
    "- Examine performance of multiclass classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digits Example\n",
    "\n",
    "To begin, we will return to the MNIST handwritten digit dataset.  First, we examine a binary classifier for the data based on whether or not a digit is a 5.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ConnectionResetError",
     "evalue": "[Errno 54] Connection reset by peer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionResetError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6af3f8fc2d5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_mldata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MNIST original'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/datasets/mldata.py\u001b[0m in \u001b[0;36mfetch_mldata\u001b[0;34m(dataname, target_name, data_name, transpose_data, data_home)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0murlname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLDATA_BASE_URL\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mquote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mmldata_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m404\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 544\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0mhttp_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1329\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1331\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1332\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionResetError\u001b[0m: [Errno 54] Connection reset by peer"
     ]
    }
   ],
   "source": [
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make into a binary classification problem\n",
    "\n",
    "    -if less than 5 make it a 1\n",
    "    \n",
    "    -if greater than 5 then make it a 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for label in mnist['target']:\n",
    "    if label == 5:\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(mnist['data'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr = LogisticRegression()\n",
    "sgd = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[800. 660. 660. 560. 520. 540. 620. 600. 480. 520. 700. 420. 600. 720.\n 400. 660. 700. 560. 800. 480. 620. 400. 620. 680. 800. 660. 460. 700.\n 700. 740. 620.  nan 440. 580. 620. 500. 400. 560. 800. 600. 580. 580.\n 540. 800. 300. 520. 780. 400. 800. 440. 580. 420. 520. 620. 560. 620.\n 580. 440. 540. 500. 520. 660. 460. 500. 380. 540. 560. 580. 620. 640.\n 600. 660. 680. 540. 780. 460. 660. 640. 680. 800. 620. 520. 580. 620.\n 440. 640. 520. 580. 220. 600. 540. 460. 700. 540. 640. 360. 460. 660.\n 680. 580. 800. 460. 800. 640. 700. 520. 700. 580. 420. 700. 700. 500.\n 520. 760. 580. 580. 540. 800. 440. 620. 640. 520. 660. 640. 640. 500.\n 400. 540. 660. 440. 580. 540. 680. 800. 480. 400. 400. 600. 440. 520.\n 740. 540. 380. 600. 620. 480. 700. 680. 580. 520. 680. 540. 500. 600.\n 520. 620. 560. 740. 740. 560. 520. 660. 540. 640. 560. 400. 600. 560.\n 740. 500. 560. 700. 420. 480. 500. 360. 680. 480. 800. 560. 720. 800.\n 400. 580. 760. 580. 660. 480. 660. 560. 600. 780. 680. 480. 640. 720.\n 560. 540. 660. 520. 740. 380. 620. 540. 520. 560. 700. 520. 620. 800.\n 800. 380. 700. 700. 540. 800. 620. 660. 580. 660. 680. 620. 600. 600.\n 520. 500. 600. 480. 680. 660. 540. 340. 620. 640. 600. 600. 700. 560.\n 640. 700. 720. 500. 680. 580. 620. 460. 760. 620. 540. 740. 800. 560.\n 460. 680. 720. 620. 560. 720. 580. 540. 620. 640. 620. 480. 620. 760.\n 640. 660. 520. 680. 520. 500. 580. 560. 600. 560. 680. 560. 620. 500.\n 620. 660. 740. 520. 700. 760. 600. 300. 400. 360. 480. 540. 520. 600.\n 460. 600. 620. 500. 640. 400.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-554a38f602de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0;32m-> 1216\u001b[0;31m                          order=\"C\")\n\u001b[0m\u001b[1;32m   1217\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;31m# To ensure that array flags are maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[800. 660. 660. 560. 520. 540. 620. 600. 480. 520. 700. 420. 600. 720.\n 400. 660. 700. 560. 800. 480. 620. 400. 620. 680. 800. 660. 460. 700.\n 700. 740. 620.  nan 440. 580. 620. 500. 400. 560. 800. 600. 580. 580.\n 540. 800. 300. 520. 780. 400. 800. 440. 580. 420. 520. 620. 560. 620.\n 580. 440. 540. 500. 520. 660. 460. 500. 380. 540. 560. 580. 620. 640.\n 600. 660. 680. 540. 780. 460. 660. 640. 680. 800. 620. 520. 580. 620.\n 440. 640. 520. 580. 220. 600. 540. 460. 700. 540. 640. 360. 460. 660.\n 680. 580. 800. 460. 800. 640. 700. 520. 700. 580. 420. 700. 700. 500.\n 520. 760. 580. 580. 540. 800. 440. 620. 640. 520. 660. 640. 640. 500.\n 400. 540. 660. 440. 580. 540. 680. 800. 480. 400. 400. 600. 440. 520.\n 740. 540. 380. 600. 620. 480. 700. 680. 580. 520. 680. 540. 500. 600.\n 520. 620. 560. 740. 740. 560. 520. 660. 540. 640. 560. 400. 600. 560.\n 740. 500. 560. 700. 420. 480. 500. 360. 680. 480. 800. 560. 720. 800.\n 400. 580. 760. 580. 660. 480. 660. 560. 600. 780. 680. 480. 640. 720.\n 560. 540. 660. 520. 740. 380. 620. 540. 520. 560. 700. 520. 620. 800.\n 800. 380. 700. 700. 540. 800. 620. 660. 580. 660. 680. 620. 600. 600.\n 520. 500. 600. 480. 680. 660. 540. 340. 620. 640. 600. 600. 700. 560.\n 640. 700. 720. 500. 680. 580. 620. 460. 760. 620. 540. 740. 800. 560.\n 460. 680. 720. 620. 560. 720. 580. 540. 620. 640. 620. 480. 620. 760.\n 640. 660. 520. 680. 520. 500. 580. 560. 600. 560. 680. 560. 620. 500.\n 620. 660. 740. 520. 700. 760. 600. 300. 400. 360. 480. 540. 520. 600.\n 460. 600. 620. 500. 640. 400.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "lgr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lgr.score is the accuracy= \n",
    "TP + TN / (TP + TN + FP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Alternative Classifier\n",
    "\n",
    "Just for comparison, we can implement a Stochastic Gradient Descent classifier.  We will discuss the algorithm more next class, for now let's just use it to compare against our Logisitic Regression example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't a great indicator because we've grouped 50% of the data into one category and the other 50% into one other category\n",
    "That is a lot of leeway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9663428571428572"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing to Baseline\n",
    "\n",
    "We can use the `DummyClassifier` to generate a baseline estimation that only guesses the majority class everytime regardless of the data.  This is akin to examining the baseline of a dataset.  Let's see how this example does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dum_dum = DummyClassifier(strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=None, strategy='most_frequent')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dum_dum.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9087238095238095"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dum_dum.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_pred = dum_dum.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm. What's going on here?  It seems that simply guessing 0 gives a fairly \"accurate\" classifier.  This is because the accuracy is simply the number guessed correctly out of the total number of options.  In this example, 1 in 10 are 5's.  Let's consider the confusion matrix for a situation where there are 1000 digits and 100 of them are 5's.  \n",
    "\n",
    "**CONFUSION MATRIX**\n",
    "\n",
    "<table style=\"width:60%\">\n",
    "  <tr>\n",
    "    <th> </th>\n",
    "    <th>Predicted Negative</th> \n",
    "    <th>Predicted Positive</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Actually Negative</td>\n",
    "    <td> True Negative</td> \n",
    "      <td> False Positive</td>\n",
    "\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Actually Positive</td>\n",
    "    <td>False Negative</td>\n",
    "    <td>True Positive</td>\n",
    "</table>\n",
    "\n",
    "**EXAMPLE**\n",
    "\n",
    "|     |  Predict Neg | Predict Pos |\n",
    "| ----- | ----- | ------ |\n",
    "| Really Negative |  900  |  0  |\n",
    "| Really Positive | 100  |  0  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting sgd results\n",
    "sgd_prd = sgd.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting logistic results\n",
    "lgr_prd = lgr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46850,   858],\n",
       "       [  909,  3883]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sgd confustion matrix\n",
    "confusion_matrix(y_train, sgd_prd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[47343,   365],\n",
       "       [  797,  3995]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logistic regression \n",
    "confusion_matrix(y_train, lgr_prd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[47708,     0],\n",
       "       [ 4792,     0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dummy predictor\n",
    "confusion_matrix(y_train, d_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beyond Accuracy\n",
    "\n",
    "**Accuracy**: \n",
    "\n",
    "Percent classified correctly.\n",
    "\n",
    "$$\\displaystyle \\frac{TP +TN}{TP + FP + TN + FN}$$\n",
    "\n",
    "\n",
    "\n",
    "**Precision**:\n",
    "\n",
    "More refined metrics begin with Precision, which is the proportion of positives that are really true positives.  Here, to increase precision, we want to decrease False Positive results.\n",
    "\n",
    "\n",
    " $$\\displaystyle \\frac{TP}{TP + FP}$$\n",
    " \n",
    " \n",
    "**Recall**:\n",
    "\n",
    "If we consider the number of true positives in terms of all the real positives, we have recall.  To get better recall, we want to avoid False Negatives.\n",
    "\n",
    " $$\\displaystyle \\frac{TP}{TP + FN}$$\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for Logistic Regression model:\n",
      "0.98\n",
      "Accuracy score for SGD model: \n",
      "0.97\n",
      "Accuracy score for Dummy Classifer model: \n",
      "0.91\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score for Logistic Regression model:\\n{:.2f}\".format(accuracy_score(y_train, lgr_prd)))\n",
    "print(\"Accuracy score for SGD model: \\n{:.2f}\".format(accuracy_score(y_train, sgd_prd)))\n",
    "print(\"Accuracy score for Dummy Classifer model: \\n{:.2f}\".format(accuracy_score(y_train, d_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score for Logistic Regression model: \n",
      " 0.9162844036697247\n",
      "Precision score for SGD model: \n",
      " 0.8190255220417634\n",
      "Precision score for Dummy Classifer model: \n",
      " 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision score for Logistic Regression model: \\n\", precision_score(y_train, lgr_prd))\n",
    "print(\"Precision score for SGD model: \\n\", precision_score(y_train, sgd_prd))\n",
    "print(\"Precision score for Dummy Classifer model: \\n\", precision_score(y_train, d_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score for Logistic Regression model: \n",
      " 0.8336811352253757\n",
      "Recall score for SGD model: \n",
      " 0.8103088480801336\n",
      "Recall score for Dummy Classifer model: \n",
      " 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall score for Logistic Regression model: \\n\", recall_score(y_train, lgr_prd))\n",
    "print(\"Recall score for SGD model: \\n\", recall_score(y_train, sgd_prd))\n",
    "print(\"Recall score for Dummy Classifer model: \\n\", recall_score(y_train, d_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression full report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99     47708\n",
      "          1       0.92      0.83      0.87      4792\n",
      "\n",
      "avg / total       0.98      0.98      0.98     52500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression full report\\n\", classification_report(y_train,lgr_prd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD full report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98     47708\n",
      "          1       0.82      0.81      0.81      4792\n",
      "\n",
      "avg / total       0.97      0.97      0.97     52500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"SGD full report\\n\", classification_report(y_train,sgd_prd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy full report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95     47708\n",
      "          1       0.00      0.00      0.00      4792\n",
      "\n",
      "avg / total       0.83      0.91      0.87     52500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dummy full report\\n\", classification_report(y_train,d_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Admissions Example\n",
    "\n",
    "Now, let's predict the `admit` class from the `gre` variable.  Be sure to use a train test split and cross validation.\n",
    "\n",
    "- Load Dataset\n",
    "- Examine Variables\n",
    "- Deal with missing and non-numeric\n",
    "- Split\n",
    "- Create Dummy Classifier\n",
    "- Create and fit a Logistic Classifier with Cross Validation\n",
    "- Compare and discuss the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions = pd.read_csv('data/admissions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit    gre   gpa  prestige\n",
       "0      0  380.0  3.61       3.0\n",
       "1      1  660.0  3.67       3.0\n",
       "2      1  800.0  4.00       1.0\n",
       "3      1  640.0  3.19       4.0\n",
       "4      0  520.0  2.93       4.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions = admissions.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a2446fc18>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(x = 'admit', y = 'gpa', data = admissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#dummies = pd.DataFrame(pd.get_dummies(admissions.admit, drop_first =True))\n",
    "dummies = pd.DataFrame(pd.get_dummies(admissions.admit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  1  0\n",
       "1  0  1\n",
       "2  0  1\n",
       "3  0  1\n",
       "4  1  0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['admit', 'gre', 'gpa', 'prestige'], dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "Name: 0, dtype: uint8"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies.columns\n",
    "dummies[0].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = admissions.gre\n",
    "X = X.dropna()\n",
    "y = dummies[0]\n",
    "y = y.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr = LogisticRegression()\n",
    "sgd = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr.fit(X_train.values.reshape(-1,1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       1.00      0.69      0.82       100\n",
      "\n",
      "avg / total       1.00      0.69      0.82       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayanadawkins/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train.values.reshape(-1,1), y_train)\n",
    "pred = clf.predict(X_test.values.reshape(-1,1))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
